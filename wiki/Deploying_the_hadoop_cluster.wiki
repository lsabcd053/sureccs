#summary One-sentence summary of this page.
#labels Featured,Phase-Support,Phase-QA

= Introduction =
This would help you deploy the hadoop cluster, namenode and datanodes included, in a linux-like system. We have done a very good test in ubuntu 8.04, and we are pretty sure that other os could also be available.


= Details =

前期：
（1）安装sun的JDK
sudo apt-get install sun-java6-jdk，如果你不确定是不是已经安装过了JDK，可以用命令：java -version来看看。
如果说，java version不是sun的，或者是说java不是内部命令，那么就需要安装了。
（2）配置JDK环境变量
JDK一般默认安装到/usr/lib/jvm/java-6-sun下面，包括可执行程序以及类库都在这下面，可以用cd /usr/lib/jvm/java-6-sun命令查看一下。
配置路径，一个是/etc/environment文件，一个是~/.bashrc文件，分别是这样的：
/etc/environment文件：
CLASSPATH=/usr/lib/jvm/java-6-sun/lib
JAVA_HOME=/usr/lib/jvm/java-6-sun
~/.bashrc的最末行加上
export JAVA_HOME=/usr/lib/jvm/java-6-sun
export CLASSPATH=.:$JAVA_HOME/lib/dt.jar:$JAVA_HOME/lib/tools.jar
export PATH=.:$PATH:$JAVA_HOME/bin:$JAVA_HOME/jre/bin
（3）安装SSH Server用以下命令来安装：
sudo apt-get install ssh
sudo apt-get install rsync
如果出现版本不一样的问题，先将已经装载的server或client卸载，然后重装。
（4）免密码ssh配置
生成密钥，命令如下：
sudo ssh-keygen -t dsa -P '' -f ~/.ssh/id_dsa
sudo cat ~/.ssh/id_dsa.pub >> ~/.ssh/authorized_keys
配置完成后，执行ssh localhsot,确认每台机器都可以使用ssh
（5）在所有机器修改 /etc/hosts文件
192.168.XXX.XXX     namenode	//192.168.66.101  xuwq-1				
192.168.XXX.XXX     datanode 	//192.168.66.107  cis
（6）将namenode服务器上的authorized_keys的内容加到datanode台机器的authorized_keys文件中。让namenode可以不需要密码访问datanode服务器
sudo scp authorized_keys XXX:/home/XXX/.ssh/	// cis:/home/xuwq/.ssh/ 或者直接用移动介质拷贝
ssh XXX 					// ssh cis
确认namenode可以免密码访问每台datanode

安装配置HDFS系统:
（1）配置Hadoop环境变量 
在/etc/environment文件尾添加：
HADOOP_HOME=/home/xuwq/hadoop-0.18.3
HADOOP_CONF_DIR=$HADOOP_HOME/conf  
HADOOP_LOG_DIR=/home/xuwq/hadoop-0.18.3/log
在~/.bashrc文件尾添加:
HADOOP_HOME=/home/xuwq/hadoop-0.18.3 #hadoop的主目录  
export HADOOP_HOME
HADOOP_CONF_DIR=$HADOOP_HOME/conf   #hadoop的配置文件目录
export HADOOP_CONF_DIR
HADOOP_LOG_DIR=/home/xuwq/hadoop-0.18.3/log    #存放运行日志目录  
export HADOOP_LOG_DIR  
export PATH=$PATH:$HADOOP_HOME/bin   //这一句可以由下面一句替代，将JDK和Hadoop的路径写在一起
export PATH=.:$PATH:$JAVA_HOME/bin:$JAVA_HOME/jre/bin:$HADOOP_HOME/bin
修改完毕后需要重启。
（2）修改hadoop的conf/masters和conf/slaves文件
conf/masters	内容为namenode名，xuwq-1
conf/slaves	内容为datanode名，cis
（3）修改conf/hadoop-env.sh文件
添加jdk路径	export JAVA_HOME=/usr/lib/jvm/java-6-sun 
（4）修改conf/hadoop-site.xml
<configuration>
   <property>  
      <name>fs.default.name</name>	//namenode的配置，机器名加端口  
      <value>hdfs://XXX:54310/</value>	//hdfs://xuwq-1:54310
   </property>
   <property>
     <name>mapred.job.tracker</name>	//JobTracker的配置，机器名加端口  
      <value>hdfs://XXX:54311</value>	//hdfs://xuwq-1:54310
   </property>
   <property>
      <name>dfs.replication</name>	//数据备份的数量，默认是3  
      <value>1</value>			//这里是1台namenode，1台datanode，所以value=1，建议value值小于等于datanode的数量
   </property>
   <property> 
</configuration>
（5）将hadoop的整体环境拷贝到datanode上面去	// datanode = cis
 scp -r /home/XXX/hadoop-0.18.3 XXX:/home/XXX/hadoop-0.18.3	//scp -r /home/xuwq-1/hadoop-0.18.3 cis://home/xuwq/hadoop-0.18.3
 (6)启动集群
先要格式化namenode, 执行hadoop namenode -format
然后启动hdfs文件系统，执行start-all.sh，启动后可以用jps查看进程
conf/masters文件里的机器运行的进程有NameNode, SecondaryNameNode, JobTracker
conf/slaves文件里的机器运行的进程有DataNode, TaskTracker
（7）停止集群
stop-all.sh

例子:
例1：
# 先将待测的文件放到本地文件系统的/home/test-in目录
$ mkdir test-in
$ cd test-in
$ echo "hello world bye world cdh" >file1.txt  
$ echo "hello hadoop goodbye hadoop" >file2.txt
# 将本地文件系统上的 /home/test-in 目录拷到 HDFS 的根目录上，目录名改为 input
$ hadoop fs –put test-in input 
#查看执行结果:
$ hadoop jar hadoop-0.19.1/hadoop-0.19.1-examples.jar wordcount input output
# 将文件从 HDFS 拷到本地文件系统中再查看：
$ hadoop fs -get output output
$ cat output/*
# 也可以直接查看
$ hadoop fs -cat output/*

例2：（文档中例）
将输入文件拷贝到分布式文件系统：
$ hadoop fs -put hadoop-0.18.3/conf input
运行发行版提供的示例程序：
$ hadoop jar hadoop-0.18.3/hadoop-*-examples.jar grep input output 'dfs[a-z.]+'
查看输出文件：
将输出文件从分布式文件系统拷贝到本地文件系统查看：
$ hadoop fs -get output output
$ cat output/*
或者
在分布式文件系统上查看输出文件：
$ hadoop fs -cat output/*

注意问题：
（1）所有机器的机器名必须不同，但是要保证每台机器上均有一位相同的用户
（2）可能会遇到HADOOP-1212的bug
org.apache.hadoop.dfs.DataNode: java.io.IOException: Incompatible namespaceIDs in the logs of a datanode.............. 
原因如下：
hadoop格式化时重新创建namenodeID而在datanode的tmp/dfs/data中包含上次format留下的ID,格式化清空namenode的数据但是保留了datanode的数据
解决方案是这样的：
(1) stop-all.sh停止所有进程；
(2）删除filesystem/data这个文件夹；	// 默认为tmp/dfs/data
(3）hadoop namenode –format重新格式化namenode；
(4) 重新启动